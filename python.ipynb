{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2776d1-ade0-4b8e-aef5-8e71afe60aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ad555f5-19b5-4a10-b8e3-63c06fa85e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d438923-8032-401f-9318-f3dc7bc6e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c591fb8-16ab-47fd-94ea-99763635c321",
   "metadata": {},
   "source": [
    "cnn network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21c7ebcf-da69-41d5-9f1c-029ad87b64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Conv2D(16, (3,3), activation = 'relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd1e547a-6b38-47af-8ed6-b3b50a915a94",
   "metadata": {},
   "source": [
    "ann network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b4f1660-c90c-457c-a30f-5830554a91c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dense(32, activation='relu'))\n",
    "cnn.add(Dense(16, activation='relu'))\n",
    "cnn.add(Dense(8, activation='relu'))\n",
    "cnn.add(Dense(4, activation='relu'))\n",
    "cnn.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf107d34-aabb-402b-bf07-fa758d96a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='binary_crossentropy', optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9608e56-4fcf-4c0f-8edf-90065a3b9a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19989 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.4897 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 2/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 515ms/step - accuracy: 0.4462 - loss: 0.6939 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 3/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 496ms/step - accuracy: 0.5091 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 507ms/step - accuracy: 0.5294 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 5/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 555ms/step - accuracy: 0.5222 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c8d8a90860>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Use 'categorical' class_mode in the generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\srija\\Desktop\\study\\project\\Deep Learning\\dog-cat-full-dataset\\data\\train\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  \n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\srija\\Desktop\\study\\project\\Deep Learning\\dog-cat-full-dataset\\data\\test\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "cnn.fit(train_generator, steps_per_epoch=20, epochs=5, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9ee6222-8ef3-4189-89c3-05548d51e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "834172d7-6500-4cb9-92bd-0e4212df3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(r\"C:\\Users\\srija\\Desktop\\study\\project\\Deep Learning\\dog-cat-full-dataset\\data\\train\\cats\\cat.35.jpg\", target_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ec19a100-9983-4fe1-b1b8-cba1c160920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3e02291e-6e3e-4e75-8f6b-59b601c70e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0ac90956-164d-4b06-a634-f8d2857bcb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    }
   ],
   "source": [
    "p = cnn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cb6f85a0-c1df-4624-92f1-b4af7fb50d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "if p[0][0] < 0.5  : \n",
    "    print(\"Dog\")\n",
    "else : \n",
    "    print(\"Cat\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da352648-2cf4-4424-b861-ee980e88444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2846418-994f-4120-9856-ebf446aab08b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
